{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\"\"\"\n",
    "Everything in TensorFlow is based on Tensor operations.\n",
    "Tensors are (kind of) like np.arrays.\n",
    "All tensors are immutable: you can never update the contents of a\n",
    "tensor, only create a new one.\n",
    "\n",
    " - nd-arrays (1d, 2d, or even 3d and higher)\n",
    " - GPU support\n",
    " - Computational graph / Track gradients / Backpropagation\n",
    " - Immutable!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 create tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create tensors\n",
    "# scalar, rank-0 tensor\n",
    "x = tf.constant(4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(4, shape=(1,1), dtype=tf.float32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector, rank-1\n",
    "x = tf.constant([1,2,3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix, rank-2\n",
    "x = tf.constant([[1,2,3], [4,5,6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 zeros, ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones((3,3))\n",
    "print(x)\n",
    "\n",
    "x = tf.zeros((3,3))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.eye(3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 std deviation .. normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal((3,3), mean=0, stddev=1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform((3,3), minval=0, maxval=1)        ## values are between 0 and 1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.range(10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.range(start=1, limit=15, delta=3, dtype=tf.float32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.range(start=1, limit=15, delta=3, dtype=tf.float32)\n",
    "x = tf.cast(x, dtype=tf.float16)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1,2,3])\n",
    "y = tf.constant([4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.add(x,y)\n",
    "# z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = tf.subtract(x,y)\n",
    "z = x - y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.divide(x,y)\n",
    "# z = x / y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.multiply(x,y)\n",
    "# z = x * y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 tensordot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1,2,3])\n",
    "y = tf.constant([4,5,6])\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "z = tf.tensordot(x,y, axes=1)       ## it will do element wise multiplication and then summation\n",
    "print(z)                            ## [ (1*4) + (2*5) + (3*6) ]  => 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform(shape=(2,3), minval=1, maxval=100)\n",
    "y = tf.random.uniform(shape=(2,3), minval=1, maxval=100)\n",
    "print(x)\n",
    "print()\n",
    "print(y)\n",
    "print()\n",
    "z = tf.tensordot(x,y, axes=0)\n",
    "print(z)\n",
    "\"\"\"\n",
    "x =>  [[ x11, x12, x13 ]                    y =>  [[ y11, y12, y13 ]\n",
    "       [ x21, x22, x23 ]]                          [ y21, y22, y23 ]]\n",
    "\n",
    "x and y both are having shape of (2 row 3 columns)\n",
    "\n",
    "dot product of both matrices will be the shape of (2, 3, 2, 3)\n",
    "\n",
    "Example => \n",
    "a1 = [[ (x11 * y11), (x11 * y12), (x11 * y13) ]\n",
    "      [ (x11 * y21), (x11 * y22), (x11 * y23) ]]\n",
    "\n",
    "a2 = [[ (x12 * y11), (x12 * y12), (x12 * y13) ]\n",
    "      [ (x12 * y21), (x12 * y22), (x12 * y23) ]]\n",
    "\n",
    "a2 = [[ (x13 * y11), (x13 * y12), (x13 * y13) ]\n",
    "      [ (x13 * y21), (x13 * y22), (x13 * y23) ]]\n",
    "\n",
    "the above 3 result will create one metrix (1, 2, 3) of this shape ...\n",
    "like this it has 3 values in one row .. it maens (3, 2, 3) metrix\n",
    "there are 2 rows .. so the metrix shape will be (2, 3, 2, 3)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 reduce_sum , reduce_max , reduce_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1,2,3])\n",
    "y = tf.constant([4,5,6])\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "# z = tf.reduce_sum(x*y, axis=0)       ## it will do element wise multiplication and then summation\n",
    "# z = tf.reduce_max(x+y, axis=0)\n",
    "z = tf.reduce_mean(x+y, axis=0)\n",
    "print(z)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1,2,3])\n",
    "# elementwise exponentiate\n",
    "z = x ** 3\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 matrix multiplication\n",
    "matrix multiplication (shapes must match: number of columns A = number of rows B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal((2,3))\n",
    "y = tf.random.normal((3,4))\n",
    "\n",
    "z = tf.matmul(x,y)\n",
    "    ## or\n",
    "# z = x @ y\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 indexing, slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1,2,3,4],[5,6,7,8]])\n",
    "print(x[0])\n",
    "print(x[:, 0]) # all rows, column 0\n",
    "print(x[1, :]) # row 1, all columns\n",
    "print(x[1,1]) # element at 1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "# print(x[::-1])      ## reverse order of the rows\n",
    "# print(x[1:3])\n",
    "\n",
    "## specific indexes values\n",
    "list_of_indexes = tf.constant([0, 3, 5])\n",
    "print(tf.gather(x, indices= [0, 3, 5]))\n",
    "# print(tf.gather(x, indices= list_of_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform(shape=(4,4), minval=1, maxval=100)\n",
    "print(x)\n",
    "print()\n",
    "# print(x[::-1])      ## reverse order of the rows\n",
    "# print(x[1:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal((2,3))\n",
    "print(x.shape)\n",
    "x = tf.reshape(x, (3,2))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.reshape(x, (-1,2))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.reshape(x, (6))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform(shape=(4,4), minval=1, maxval=100)\n",
    "print(x)\n",
    "print()\n",
    "print(tf.transpose(x, perm=[1,0]))          ## it will convert row to columns and column to row\n",
    "\"\"\"\n",
    "if the metrix shape is (3, 4)  .. and you will do transpose (0,1)\n",
    "it means you wnat to swap the shape number ( 3,4 ) to ( 4,3 )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform(shape=(2,5,4), minval=1, maxval=100)\n",
    "print(x)\n",
    "print()\n",
    "print(tf.transpose(x, perm=[2,0,1]))          ## it will convert row to columns and column to row\n",
    "\n",
    "\"\"\"\n",
    "if the metrix shape is (2,5,4)  .. and you will do transpose (2,0,1)\n",
    "it means you wnat to swap the shape number ( 2,5,4 ) to ( 4,2,5 )\n",
    "\n",
    "earlier it was the combination of two (5,4) matrixs ...\n",
    "after transpose it has become combination of four (2,5) matrixs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 numpy to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.convert_to_tensor(x)\n",
    "print(type(x))\n",
    "# -> eager tensor = evaluates operations immediately\n",
    "# without building graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12 string tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## string tensor\n",
    "x = tf.constant(\"alpha\")\n",
    "print(x)\n",
    "\n",
    "x = tf.constant([\"alpha\", \"beta\", \"gamma\"])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13 variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable\n",
    "# A tf.Variable represents a tensor whose value can be\n",
    "# changed by running ops on it\n",
    "# Used to represent shared, persistent state your program manipulates\n",
    "# Higher level libraries like tf.keras use tf.Variable to store model parameters.\n",
    "b = tf.Variable([[1.0, 2.0, 3.0]])\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "\n",
    "# -------------------- Transformer Model Definitions -------------------- #\n",
    "\n",
    "# Scaled Dot-Product Attention\n",
    "class ScaledDotProductAttention(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def call(self, queries, keys, values, mask):\n",
    "        # queries, keys, values: (batch_size, num_heads, seq_len, depth)\n",
    "        matmul_qk = tf.matmul(queries, keys, transpose_b=True)  # (batch_size, num_heads, seq_len, seq_len)\n",
    "\n",
    "        # Scale matmul_qk\n",
    "        dk = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        # Add the mask to the scaled tensor.\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)  # Large negative value to mask\n",
    "\n",
    "        # Softmax on the last axis (seq_len_k)\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (batch_size, num_heads, seq_len, seq_len)\n",
    "\n",
    "        output = tf.matmul(attention_weights, values)  # (batch_size, num_heads, seq_len, depth)\n",
    "\n",
    "        return output, attention_weights\n",
    "\n",
    "# Multi-Head Attention\n",
    "class MultiHeadAttention(layers.Layer):\n",
    "    def __init__(self, embed_size, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert embed_size % num_heads == 0, \"Embedding size must be divisible by num_heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_size = embed_size\n",
    "        self.depth = embed_size // num_heads\n",
    "\n",
    "        self.wq = layers.Dense(embed_size)  # Query weight\n",
    "        self.wk = layers.Dense(embed_size)  # Key weight\n",
    "        self.wv = layers.Dense(embed_size)  # Value weight\n",
    "\n",
    "        self.dense = layers.Dense(embed_size)  # Final dense layer\n",
    "\n",
    "        self.attention = ScaledDotProductAttention()\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result to shape (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])  # (batch_size, num_heads, seq_len, depth)\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        # Linear layers\n",
    "        q = self.wq(q)  # (batch_size, seq_len_q, embed_size)\n",
    "        k = self.wk(k)  # (batch_size, seq_len_k, embed_size)\n",
    "        v = self.wv(v)  # (batch_size, seq_len_v, embed_size)\n",
    "\n",
    "        # Split heads\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scaled_attention, attention_weights = self.attention(q, k, v, mask)\n",
    "        # scaled_attention: (batch_size, num_heads, seq_len_q, depth)\n",
    "\n",
    "        # Transpose and reshape\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.num_heads * self.depth))  # (batch_size, seq_len_q, embed_size)\n",
    "\n",
    "        # Final linear layer\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, embed_size)\n",
    "\n",
    "        return output, attention_weights\n",
    "\n",
    "# Position-wise Feed-Forward Network\n",
    "class PositionWiseFeedForward(layers.Layer):\n",
    "    def __init__(self, embed_size, forward_expansion):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = layers.Dense(forward_expansion * embed_size, activation='relu')\n",
    "        self.fc2 = layers.Dense(embed_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.fc2(self.fc1(x))\n",
    "\n",
    "# Encoder Layer\n",
    "class EncoderLayer(layers.Layer):\n",
    "    def __init__(self, embed_size, num_heads, forward_expansion, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(embed_size, num_heads)\n",
    "        self.ffn = PositionWiseFeedForward(embed_size, forward_expansion)\n",
    "\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = layers.Dropout(dropout)\n",
    "        self.dropout2 = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, mask, training):\n",
    "        # Multi-Head Attention\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # Self-attention\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # Residual connection\n",
    "\n",
    "        # Feed-Forward Network\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # Residual connection\n",
    "\n",
    "        return out2\n",
    "\n",
    "# Decoder Layer\n",
    "class DecoderLayer(layers.Layer):\n",
    "    def __init__(self, embed_size, num_heads, forward_expansion, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.mha1 = MultiHeadAttention(embed_size, num_heads)  # Self-attention\n",
    "        self.mha2 = MultiHeadAttention(embed_size, num_heads)  # Encoder-Decoder attention\n",
    "        self.ffn = PositionWiseFeedForward(embed_size, forward_expansion)\n",
    "\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = layers.Dropout(dropout)\n",
    "        self.dropout2 = layers.Dropout(dropout)\n",
    "        self.dropout3 = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, enc_output, src_mask, trg_mask, training):\n",
    "        # Self-Attention (masked)\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, trg_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(x + attn1)\n",
    "\n",
    "        # Encoder-Decoder Attention\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, src_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(out1 + attn2)\n",
    "\n",
    "        # Feed-Forward Network\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(out2 + ffn_output)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "\n",
    "# Encoder\n",
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, src_vocab_size, embed_size, num_layers, num_heads, forward_expansion, dropout, max_length):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.embedding = layers.Embedding(src_vocab_size, embed_size)\n",
    "        self.pos_encoding = self.positional_encoding(max_length, embed_size)\n",
    "        self.layers = [EncoderLayer(embed_size, num_heads, forward_expansion, dropout) for _ in range(num_layers)]\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "\n",
    "    def get_angles(self, pos, i, embed_size):\n",
    "        # Ensure 10000 is a float\n",
    "        angle_rates = 1.0 / tf.pow(10000.0, (2 * (i // 2)) / tf.cast(embed_size, tf.float32))\n",
    "        return pos * angle_rates\n",
    "\n",
    "    def positional_encoding(self, max_length, embed_size):\n",
    "        angle_rads = self.get_angles(\n",
    "            pos=tf.range(max_length)[:, tf.newaxis],\n",
    "            i=tf.range(embed_size)[tf.newaxis, :],\n",
    "            embed_size=embed_size\n",
    "        )\n",
    "        # Apply sin to even indices, cos to odd indices\n",
    "        angle_rads = tf.where(tf.math.mod(tf.range(embed_size), 2) == 0, \n",
    "                              tf.sin(angle_rads), \n",
    "                              tf.cos(angle_rads))\n",
    "        pos_encoding = angle_rads[tf.newaxis, ...]  # Shape: (1, max_length, embed_size)\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, mask, training):\n",
    "        seq_length = tf.shape(x)[1]\n",
    "        x = self.embedding(x)  # (batch_size, seq_length, embed_size)\n",
    "        x *= tf.math.sqrt(tf.cast(self.embed_size, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_length, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask, training)\n",
    "\n",
    "        return x  # (batch_size, seq_length, embed_size)\n",
    "\n",
    "# Decoder\n",
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, trg_vocab_size, embed_size, num_layers, num_heads, forward_expansion, dropout, max_length):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.embedding = layers.Embedding(trg_vocab_size, embed_size)\n",
    "        self.pos_encoding = self.positional_encoding(max_length, embed_size)\n",
    "        self.layers = [DecoderLayer(embed_size, num_heads, forward_expansion, dropout) for _ in range(num_layers)]\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "        self.fc_out = layers.Dense(trg_vocab_size)\n",
    "\n",
    "    def get_angles(self, pos, i, embed_size):\n",
    "        # Ensure 10000 is a float\n",
    "        angle_rates = 1.0 / tf.pow(10000.0, (2 * (i // 2)) / tf.cast(embed_size, tf.float32))\n",
    "        return pos * angle_rates\n",
    "\n",
    "    def positional_encoding(self, max_length, embed_size):\n",
    "        angle_rads = self.get_angles(\n",
    "            pos=tf.range(max_length)[:, tf.newaxis],\n",
    "            i=tf.range(embed_size)[tf.newaxis, :],\n",
    "            embed_size=embed_size\n",
    "        )\n",
    "        # Apply sin to even indices, cos to odd indices\n",
    "        angle_rads = tf.where(tf.math.mod(tf.range(embed_size), 2) == 0, \n",
    "                              tf.sin(angle_rads), \n",
    "                              tf.cos(angle_rads))\n",
    "        pos_encoding = angle_rads[tf.newaxis, ...]  # Shape: (1, max_length, embed_size)\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, enc_output, src_mask, trg_mask, training):\n",
    "        seq_length = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, embed_size)\n",
    "        x *= tf.math.sqrt(tf.cast(self.embed_size, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_length, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x, block1, block2 = layer(x, enc_output, src_mask, trg_mask, training)\n",
    "            attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "            attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "\n",
    "        out = self.fc_out(x)  # (batch_size, target_seq_len, trg_vocab_size)\n",
    "\n",
    "        return out, attention_weights\n",
    "\n",
    "# Transformer Model\n",
    "class Transformer(Model):\n",
    "    def __init__(self, src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, embed_size=512, num_layers=6, \n",
    "                 num_heads=8, forward_expansion=4, dropout=0.1, max_length=100):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(src_vocab_size, embed_size, num_layers, num_heads, forward_expansion, dropout, max_length)\n",
    "        self.decoder = Decoder(trg_vocab_size, embed_size, num_layers, num_heads, forward_expansion, dropout, max_length)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        # src: (batch_size, src_seq_len)\n",
    "        mask = tf.cast(tf.math.not_equal(src, self.src_pad_idx), dtype=tf.float32)  # (batch_size, src_seq_len)\n",
    "        mask = mask[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, src_seq_len)\n",
    "        return mask  # Broadcastable to (batch_size, num_heads, trg_seq_len, src_seq_len)\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        # trg: (batch_size, trg_seq_len)\n",
    "        seq_len = tf.shape(trg)[1]\n",
    "        # Look-ahead mask\n",
    "        look_ahead_mask = 1.0 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)  # (trg_seq_len, trg_seq_len)\n",
    "        # Padding mask\n",
    "        padding_mask = tf.cast(tf.math.not_equal(trg, self.trg_pad_idx), dtype=tf.float32)  # (batch_size, trg_seq_len)\n",
    "        padding_mask = padding_mask[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, trg_seq_len)\n",
    "        # Combine masks\n",
    "        combined_mask = tf.maximum(look_ahead_mask, 1.0 - padding_mask)  # (batch_size, trg_seq_len, trg_seq_len)\n",
    "        combined_mask = combined_mask[tf.newaxis, ...]  # (1, trg_seq_len, trg_seq_len)\n",
    "        return combined_mask  # Broadcastable to (batch_size, num_heads, trg_seq_len, trg_seq_len)\n",
    "\n",
    "    def call(self, src, trg, training):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "\n",
    "        enc_output = self.encoder(src, src_mask, training)  # (batch_size, src_seq_len, embed_size)\n",
    "        dec_output, attention_weights = self.decoder(trg, enc_output, src_mask, trg_mask, training)  # (batch_size, trg_seq_len, trg_vocab_size)\n",
    "\n",
    "        return dec_output  # logits\n",
    "\n",
    "\n",
    "\n",
    "# Constants\n",
    "src_pad_idx = 0\n",
    "trg_pad_idx = 0\n",
    "src_vocab_size = 10  # Example vocabulary size\n",
    "trg_vocab_size = 10  # Example vocabulary size\n",
    "embed_size = 128\n",
    "num_layers = 2\n",
    "num_heads = 2\n",
    "forward_expansion = 4\n",
    "dropout = 0.1\n",
    "max_length = 9  # Length of your sequences\n",
    "batch_size = 2\n",
    "epochs = 20\n",
    "\n",
    "# Sample training data\n",
    "# Source sequences (e.g., tokenized sentences)\n",
    "x = tf.constant([\n",
    "    [1, 5, 6, 4, 3, 9, 5, 2, 0],\n",
    "    [1, 8, 7, 3, 4, 5, 6, 7, 2]\n",
    "], dtype=tf.int32)\n",
    "\n",
    "# Target sequences (e.g., tokenized sentences)\n",
    "trg = tf.constant([\n",
    "    [1, 7, 4, 3, 5, 9, 2, 0, 0],\n",
    "    [1, 5, 6, 2, 4, 7, 6, 2, 0]\n",
    "], dtype=tf.int32)\n",
    "\n",
    "# Create trg_input and trg_real\n",
    "trg_input = trg[:, :-1]  # (batch_size, trg_seq_len - 1)\n",
    "trg_real = trg[:, 1:]    # (batch_size, trg_seq_len - 1)\n",
    "\n",
    "# Create training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(((x, trg_input), trg_real))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# -------------------- Loss Function -------------------- #\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    \"\"\"\n",
    "    real: (batch_size, trg_seq_len - 1)\n",
    "    pred: (batch_size, trg_seq_len - 1, trg_vocab_size)\n",
    "    \"\"\"\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, trg_pad_idx))  # (batch_size, trg_seq_len - 1)\n",
    "    loss_ = loss_object(real, pred)  # (batch_size, trg_seq_len - 1)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)  # (batch_size, trg_seq_len - 1)\n",
    "    loss_ *= mask  # Apply the mask\n",
    "\n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)  # Scalar\n",
    "\n",
    "# -------------------- Optimizer with Learning Rate Scheduler -------------------- #\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, embed_size, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.embed_size = tf.cast(self.embed_size, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        # Implement the learning rate schedule\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.embed_size) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = CustomSchedule(embed_size)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# -------------------- Metrics -------------------- #\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "\n",
    "# -------------------- Initialize the Transformer Model -------------------- #\n",
    "\n",
    "transformer = Transformer(\n",
    "    src_vocab_size=src_vocab_size, \n",
    "    trg_vocab_size=trg_vocab_size, \n",
    "    src_pad_idx=src_pad_idx, \n",
    "    trg_pad_idx=trg_pad_idx,\n",
    "    embed_size=embed_size, \n",
    "    num_layers=num_layers, \n",
    "    num_heads=num_heads, \n",
    "    forward_expansion=forward_expansion, \n",
    "    dropout=dropout, \n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "# -------------------- Training Step -------------------- #\n",
    "\n",
    "@tf.function\n",
    "def train_step(src, trg_input, trg_real):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass\n",
    "        predictions = transformer(src, trg_input, training=True)  # (batch_size, trg_seq_len - 1, trg_vocab_size)\n",
    "        loss = loss_function(trg_real, predictions)\n",
    "\n",
    "    # Compute gradients\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    # Apply gradients\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    # Update metrics\n",
    "    train_loss(loss)\n",
    "\n",
    "# -------------------- Training Loop -------------------- #\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss.reset_states()  # Reset the metrics at the start of each epoch\n",
    "\n",
    "    for batch, ((src_batch, trg_input_batch), trg_real_batch) in enumerate(train_dataset):\n",
    "        train_step(src_batch, trg_input_batch, trg_real_batch)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {train_loss.result():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Layer, Dense, Embedding, LayerNormalization, Dropout\n",
    "import numpy as np\n",
    "\n",
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, embed_size, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_size = embed_size\n",
    "        self.head_dim = embed_size // num_heads\n",
    "\n",
    "        assert embed_size % num_heads == 0, \"Embedding size must be divisible by number of heads\"\n",
    "\n",
    "        self.values = Dense(embed_size)\n",
    "        self.keys = Dense(embed_size)\n",
    "        self.queries = Dense(embed_size)\n",
    "        self.fc_out = Dense(embed_size)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.head_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, queries, keys, values, mask):\n",
    "        batch_size = tf.shape(queries)[0]\n",
    "\n",
    "        q = self.split_heads(self.queries(queries), batch_size)\n",
    "        k = self.split_heads(self.keys(keys), batch_size)\n",
    "        v = self.split_heads(self.values(values), batch_size)\n",
    "\n",
    "        attention_scores = tf.matmul(q, k, transpose_b=True)\n",
    "        if mask is not None:\n",
    "            attention_scores += (mask * -1e9)\n",
    "\n",
    "        attention_weights = tf.nn.softmax(attention_scores / tf.math.sqrt(tf.cast(self.head_dim, tf.float32)), axis=-1)\n",
    "        out = tf.matmul(attention_weights, v)\n",
    "        out = tf.transpose(out, perm=[0, 2, 1, 3])\n",
    "        out = tf.reshape(out, (batch_size, -1, self.embed_size))\n",
    "        return self.fc_out(out)\n",
    "\n",
    "class PositionwiseFeedForward(Layer):\n",
    "    def __init__(self, embed_size, ff_dim, dropout_rate=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.fc1 = Dense(ff_dim, activation='relu')\n",
    "        self.fc2 = Dense(embed_size)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_size, num_heads, ff_dim, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(embed_size, num_heads)\n",
    "        self.ffn = PositionwiseFeedForward(embed_size, ff_dim, dropout_rate)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        attn_output = self.attention(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        x = self.layernorm1(x + attn_output)\n",
    "        ffn_output = self.ffn(x)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(x + ffn_output)\n",
    "\n",
    "class Transformer(keras.Model):\n",
    "    def __init__(self, src_vocab_size, trg_vocab_size, embed_size, num_layers, num_heads, ff_dim, dropout_rate=0.1, max_length=500):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.src_vocab_size = src_vocab_size\n",
    "        self.trg_vocab_size = trg_vocab_size\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.src_embedding = Embedding(src_vocab_size, embed_size)\n",
    "        self.trg_embedding = Embedding(trg_vocab_size, embed_size)\n",
    "        self.positional_encoding = self.create_positional_encoding()\n",
    "\n",
    "        self.encoder_layers = [TransformerBlock(embed_size, num_heads, ff_dim, dropout_rate) for _ in range(num_layers)]\n",
    "        self.decoder_layers = [TransformerBlock(embed_size, num_heads, ff_dim, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.fc_out = Dense(trg_vocab_size)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def create_positional_encoding(self):\n",
    "        pos = np.arange(self.max_length)[:, np.newaxis]\n",
    "        i = np.arange(self.embed_size)[np.newaxis, :]\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(self.embed_size))\n",
    "        angle_rads = pos * angle_rates\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        return tf.constant(angle_rads[np.newaxis, :], dtype=tf.float32)\n",
    "\n",
    "    def call(self, src, trg, src_mask=None, trg_mask=None):\n",
    "        src_embedded = self.src_embedding(src) + self.positional_encoding[:, :tf.shape(src)[1], :]\n",
    "        trg_embedded = self.trg_embedding(trg) + self.positional_encoding[:, :tf.shape(trg)[1], :]\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for layer in self.encoder_layers:\n",
    "            enc_output = layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = trg_embedded\n",
    "        for layer in self.decoder_layers:\n",
    "            dec_output = layer(dec_output, trg_mask)\n",
    "\n",
    "        final_output = self.fc_out(dec_output)\n",
    "        return final_output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
